{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load the pre-trained model and tokenizer\n",
    "model_name = \"gpt2\"  # You can use a different model like GPT-J or T5\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "octave = \"\"\"\n",
    "Orlando, whose soul was full of rage and grief,\n",
    "Met with Rinaldo, whose valor was known to all.\n",
    "They faced each other with swords drawn, their eyes locked\n",
    "In a battle where neither would retreat.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the prompt\n",
    "prompt = f\"Passage: {octave}\\n\\nQuestion: Are there any character encounters in this passage? If so, which characters are involved?\"\n",
    "\n",
    "# Tokenize the input text\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "# Generate a response using the model\n",
    "outputs = model.generate(inputs[\"input_ids\"], max_length=200, num_return_sequences=1, no_repeat_ngram_size=2)\n",
    "\n",
    "# Decode the output tokens to get the response\n",
    "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
